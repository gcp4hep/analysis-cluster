jupyterhub:
  singleuser:
    startTimeout: 3600
    # Defines the default image
    image:
      name: eu.gcr.io/gke-dev-311213/jupyter-coffea
      tag: "20210518"
    extraEnv:
      ATLAS_LOCAL_ROOT_BASE: /cvmfs/atlas.cern.ch/repo/ATLASLocalRootBase
    profileList:
      # This profile was for initial testing only
      # - display_name: "pyHEP environment"
      #  description: "coffea, uproot..."
      #  default: true
      - display_name: "PHYSLITE environment"
        description: "environment for experiments with DAOD_PHYSLITE with uproot, awkward etc."
        kubespawner_override:
          image: eu.gcr.io/gke-dev-311213/jupyter-physlite:20210709
      - display_name: "ML environment"
        description: "keras, flatbuffers, joblib, pillow, pytz, scikit-learn, scipy, uproot, root-numpy"
        kubespawner_override:
          image: eu.gcr.io/gke-dev-311213/jupyter-ml-gpu:20211129
      - display_name: "ML environment with T4 GPU"
        description: "Similar to the previous ML environment, but it boots a VM with a GPU just for YOU. Only to be used when working on ML-GPU applications. Setting up your notebook will take 10 minutes or more."
        kubespawner_override:
           image: eu.gcr.io/gke-dev-311213/jupyter-ml-gpu:20211129
           node_selector:
             cloud.google.com/gke-accelerator: nvidia-tesla-t4
           extra_resource_limits:
             nvidia.com/gpu: "1"
      - display_name: "ML environment with P100 GPU"
        description: "Similar to the previous ML environment, but it boots a VM with a GPU just for YOU. Only to be used when working on ML-GPU applications. Setting up your notebook will take 10 minutes or more."
        kubespawner_override:
           image: eu.gcr.io/gke-dev-311213/jupyter-ml-gpu:20211129
           node_selector:
             cloud.google.com/gke-accelerator: nvidia-tesla-p100
           extra_resource_limits:
             nvidia.com/gpu: "1"
      - display_name: "ML environment with K80 GPU"
        description: "Similar to the previous ML environment, but it boots a VM with a GPU just for YOU. Only to be used when working on ML-GPU applications. Setting up your notebook will take 10 minutes or more."
        kubespawner_override:
           image: eu.gcr.io/gke-dev-311213/jupyter-ml-gpu:20211129
           node_selector:
             cloud.google.com/gke-accelerator: nvidia-tesla-k80
           extra_resource_limits:
             nvidia.com/gpu: "1"
    storage:
      extraVolumes:
        - name: atlas
          persistentVolumeClaim:
            claimName: cvmfs-config-atlas
            readOnly: true
        - name: atlas-condb
          persistentVolumeClaim:
            claimName: cvmfs-config-atlas-condb
            readOnly: true
        - name: atlas-nightlies
          persistentVolumeClaim:
            claimName: cvmfs-config-atlas-nightlies
            readOnly: true
        - name: grid
          persistentVolumeClaim:
            claimName: cvmfs-config-grid
            readOnly: true
        - name: sft
          persistentVolumeClaim:
            claimName: cvmfs-config-sft
            readOnly: true
        - name: sft-nightlies
          persistentVolumeClaim:
            claimName: cvmfs-config-sft-nightlies
            readOnly: true
        - name: unpacked
          persistentVolumeClaim:
            claimName: cvmfs-config-unpacked
            readOnly: true
      extraVolumeMounts:
        - name: atlas
          mountPath: /cvmfs/atlas.cern.ch
        - name: atlas-condb
          mountPath: /cvmfs/atlas-condb.cern.ch
        - name: atlas-nightlies
          mountPath: /cvmfs/atlas-nightlies.cern.ch
        - name: grid
          mountPath: /cvmfs/grid.cern.ch
        - name: sft
          mountPath: /cvmfs/sft.cern.ch
        - name: sft-nightlies
          mountPath: /cvmfs/sft-nightlies.cern.ch
        - name: unpacked
          mountPath: /cvmfs/unpacked.cern.ch

  proxy:
    secretToken: <SECRET_TOKEN>

  hub:
    services:
      dask-gateway:
        apiToken: <API_TOKEN>

    networkPolicy:
      enabled: False

    config:
      Authenticator:
        admin_users:
          - ...
        allowed_users:
          - ...
      DummyAuthenticator:
        password: password
      JupyterHub:
        authenticator_class: dummy

dask-gateway:
  traefik:
    service:
      type: LoadBalancer

  gateway:
    auth:
      jupyterhub:
        apiToken: <API_TOKEN>

    backend:
      scheduler:
        # Cores request/limit for the scheduler.
        cores:
          request: 1
          limit: 1

        # Memory request/limit for the scheduler.
        memory:
          request: "32G"
          limit: "100G"

      worker:
        extraPodConfig:
          tolerations:
            - key: "dask"
              operator: "Equal"
              value: "worker"
              effect: "NoSchedule"
          nodeSelector:
            dask: "worker"

    extraConfig:
      optionHandler: |
        from dask_gateway_server.options import Options, Integer, Float, String
        def option_handler(options):
            if ":" not in options.image:
                raise ValueError("When specifying an image you must also provide a tag")
            return {
                "image": options.image,
            "worker_cores": options.worker_cores,
            "worker_memory": int(options.worker_memory * 2 ** 30),
            }
        c.Backend.cluster_options = Options(
            Integer("worker_cores", default=1, min=1, max=8, label="Worker Cores"),
            Float("worker_memory", default=1, min=1, max=32, label="Worker Memory (GiB)"),
            String("image", default="eu.gcr.io/gke-dev-311213/dask-gateway-coffea:20210518", label="Image"),
            handler=option_handler,
        )
